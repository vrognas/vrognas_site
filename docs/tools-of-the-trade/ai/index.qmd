---
title: "AI (artificial intelligence)"
date: last-modified
---

:::{.callout-caution title="Under construction"}
:::

* Start with brainstorming/planning, then move on to implementation
* Commit often with small, focused commits
* Always write a test so that the AI can iterate
* New problem, new chat. Clear the context; start fresh.

**Anthropic 4D framework for "AI Fluency":**

* **Delegation:** Deciding what work to do with AI vs. yourself
* **Description:** Communicating effectively (e.g., context/prompt engineering)
* **Discernment:** Evaluating AI output/behavior
* **Diligence:** Ensuring responsible AI interaction (accuracy, safety, security, accountability)

Application example: *You're using AI to help analyze a large dataset for a research paper.*

* **Delegation:** How would you divide the analytical work between yourself and the AI?
* **Description:** What context would the AI need to understand about your research question to do its share of the tasks well?
* **Discernment:** How would you verify the AI's analysis for accuracy?
* **Diligence:** What ethical considerations might arise when publishing AI-assisted research?

## Delegation

> The goal is to create the most effective human-AI partnership

1. **Problem Awareness:** Clearly define goals and the work needed, [**before**]{.red-underline} involving AI tools
2. **Platform Awareness:** Knowing through **hands-on** experience, what different AI systems can and can't do (capabilities and limitations).
3. **Task Delegation:** Strategically dividing work between you and AI
    1. **Automation:** AI executes specific tasks based on your instructions
    2. **Augmentation:** You and AI collaborate as creative thinking and task execution partners
    3. **Agency:** You configure AI to work independently on your behalf, establishing its knowledge and behavior patterns rather than just giving it specific tasks

What could be usefully automated?
Where would augmentation create more value than working separately?
What should be done by a human alone?
What could be done by an agent on your behalf?

>  "I'm preparing how to [insert task] and want to discuss with you what a delegation plan may look like for figuring out which parts I should delegate to an AI like you vs. not. Can you help me with this?"

## Description

* **Product Description:** Clearly defining what you want the AI to create
* **Process Description:** Guiding how the AI approaches your request
* **Performance Description:** Defining how you want the AI to behave during your collaboration

Before moving on to more advanced techniques such as RAG and fine-tuning, try out prompt engineering first.

### Prompt Engineering

XML tags and variables

```xml
<task>
1. Output an overview of every single dimension of my request.
2. Find points of uncertainty.
3. Ask as many clarifying questions as possible.
</task>

<request>
{{REQUEST}}
</request>

<context>
{{CONTEXT}}
</context>
```

### Fine-tuning

Fine-tuning operates inside the model.
It modifies the model's parameters by continuing gradient-based training on a domain or task dataset.
You’re updating the model’s trainable parameters, which alters its internal representation space, essentially teaching it new mappings between input tokens and contextual embeddings.
> It requires GPU clusters (often multi-node with FSDP/DeepSpeed), mixed-precision training, and PEFT methods like LoRA or QLoRA that  train only a small fraction of weights (1–5%)  to reduce compute,
> After training, the model is self-contained and fast to serve, but static. New knowledge means retraining.
> Best for behavioral adaptation: reasoning format, style, or classification logic.

A good use is for Behavior alignment or domains with static knowledge.

### Retrieval-augmented Generation (RAG)

RAG by contrast, keeps the model frozen and adds a retrieval pipeline,
> Documents are chunked (e.g., 1,000-token segments with 200 overlap) using RecursiveCharacterTextSplitter.
> Text chunks are embedded (e.g., via all-MiniLM or text-embedding-3-large) and stored in a vector DB such as Chroma or Pinecone.
> At query time, relevant chunks are retrieved by cosine similarity and appended to the prompt before generation.
> It only needs embedding inference (CPU/GPU-light) plus a retrieval service.
> Best for knowledge augmentation: dynamic Q&A, enterprise docs, or fast-changing sources.

A good use for RAG is where new knowledge is added to the database on a rapid scale, and the latest, accurate information retrieval is crucial

### Model context protocol (MCP)

A protocol for LLMs to communicate with external services and tools.

## Discernment

## Diligence

## Tools

### Models

![](../images/llm_r.png){#fig-llm-r}

### R packages

* mcptools
* btw
* ellmer
* chores
* gander
* mall

## References

* Simon P. Couch
* Sara Altman

::: {#refs}
:::
