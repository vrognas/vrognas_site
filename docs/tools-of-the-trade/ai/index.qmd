---
title: "Artificial Intelligence (AI) and Large Language Models (LLMs)"
date: last-modified
---

:::{.callout-caution title="Under construction"}
:::

* Start with brainstorming/planning, then move on to implementation
* Commit often with small, focused commits
* Always write a test so that the AI can iterate
* New problem, new chat. Clear the context; start fresh.

**Anthropic 4D framework for "AI Fluency":**

* **Delegation:** Deciding what work to do with AI vs. yourself
* **Description:** Communicating effectively (e.g., context/prompt engineering)
* **Discernment:** Evaluating AI output/behavior
* **Diligence:** Ensuring responsible AI interaction (accuracy, safety, security, accountability)

Application example: *You're using AI to help analyze a large dataset for a research paper.*

* **Delegation:** How would you divide the analytical work between yourself and the AI?
* **Description:** What context would the AI need to understand about your research question to do its share of the tasks well?
* **Discernment:** How would you verify the AI's analysis for accuracy?
* **Diligence:** What ethical considerations might arise when publishing AI-assisted research?

## Delegation

> The goal is to create the most effective human-AI partnership

1. **Problem Awareness:** Clearly define goals and the work needed, [**before**]{.red-underline} involving AI tools
2. **Platform Awareness:** Knowing through **hands-on** experience, what different AI systems can and can't do (capabilities and limitations).
3. **Task Delegation:** Strategically dividing work between you and AI
    1. **Automation:** AI executes specific tasks based on your instructions
    2. **Augmentation:** You and AI collaborate as creative thinking and task execution partners
    3. **Agency:** You configure AI to work independently on your behalf, establishing its knowledge and behavior patterns rather than just giving it specific tasks

What could be usefully automated?
Where would augmentation create more value than working separately?
What should be done by a human alone?
What could be done by an agent on your behalf?

>  "I'm preparing how to [insert task] and want to discuss with you what a delegation plan may look like for figuring out which parts I should delegate to an AI like you vs. not. Can you help me with this?"

## Description

There is much similarity between describing the task to an AI and describing it to a human.

* **Product Description:** What you want, the end result
    * Output, format, audience, style, etc
* **Process Description:** The way to success, the thought process
    * Specific approaches, tools, methods, data, preferred order, etc
* **Performance Description:** AI general behavior
    * Role and tone; concise or detailed; challenging or supportive?

### Prompt Engineering

Before moving on to more advanced techniques such as RAG and fine-tuning, try prompt engineering first.

As a first step, **ask the AI itself to help improve your prompt**; successful prompting is **iterative**.

A good prompt consists of the following:

* **Context:** Be specific about **what you want**, **why** you want it, and the relevant **background**
* **Examples:** Demonstrate the output **style** or **format** you're looking for
* **Constraints:** Clearly define format, length, and other **output requirements**
* **Steps:** Guide the AI through multi-step reasoning
* Asking the AI to **think first:** Give space for the AI to work through its process
* **Role or tone:** Specify how you want the AI to communicate

#### Prompting tips

`<XML_tags>` and `{{VARIABLES}}`

```xml
Role: {{ROLE}}
Tone: {{TONE}}

<request>
{{REQUEST}}
</request>

Let's think step-by-step.

<steps>
1. Output an overview of every single dimension of my request.
2. Find points of uncertainty.
3. Ask as many clarifying questions as possible.
</steps>

<context>
{{CONTEXT}}
</context>

<example>
{{EXAMPLE}}
</example>

<constraints>
{{CONSTRAINTS}}
</constraints>
```

Force the model to say things out loud.

<https://ai.google.dev/gemini-api/docs/prompting-strategies>
<https://cookbook.openai.com/>
<https://docs.claude.com/en/docs/build-with-claude/prompt-engineering/overview>

### Fine-tuning

Fine-tuning operates inside the model.

This updates the model, essentially resulting in a **new model**.
After training, the model is self-contained and fast to serve, but static. New knowledge means retraining.

A good use is for **behavior alignment** (reasoning format, style, classification logic) or domains with **static knowledge**.

### Retrieval-augmented Generation (RAG)

RAG keeps the model as-is and adds a library.

A good use for RAG is as **knowledge augmentation** where new knowledge is added often, and the latest, accurate information retrieval is crucial.

### Model context protocol (MCP)

A protocol for LLMs to communicate with external services and tools.

## Discernment

## Diligence

## Tools

### Models

![](../images/llm_r.png){#fig-llm-r}

### R packages

* mcptools
* btw
* ellmer
* chores
* gander
* mall

## References

* Simon P. Couch
* Sara Altman

::: {#refs}
:::
