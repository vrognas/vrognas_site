---
title: "Artificial Intelligence (AI) and Large Language Models (LLMs)"
date: last-modified
---

:::{.callout-caution title="Under construction"}
:::

Anthropic has devised something they call "AI Fluency"---a way to approach and work with AI that outlives evanescent tips and tricks that quickly become outdated.
The proposed "4D framework" for AI Fluency rests on these four core competencies:

1. **Delegation:** Deciding what work to do with AI vs. yourself
2. **Description:** Communicating effectively (e.g., context/prompt engineering)
3. **Discernment:** Evaluating AI output/behavior
4. **Diligence:** Ensuring responsible AI interaction (accuracy, safety, security, accountability)

## Delegation

> The clarity to decide what to collaborate on with AI,  
> what to do yourself,  
> and the wisdom to know the difference.

1. **Problem Awareness:** Clearly define goals and the work needed, [**before**]{.red-underline} involving AI tools
2. **Platform Awareness:** Knowing through **hands-on** experience, what different AI systems can and can't do (capabilities and limitations).
3. **Task Delegation:** Strategically dividing work between you and AI
    1. **Automation:** AI executes specific tasks based on your instructions
    2. **Augmentation:** You and AI collaborate as creative thinking and task execution partners
    3. **Agency:** You configure AI to work independently on your behalf, establishing its knowledge and behavior patterns rather than just giving it specific tasks

What could be usefully automated?
Where would augmentation create more value than working separately?
What should be done by a human alone?
What could be done by an agent on your behalf?

>  "I'm preparing how to [insert task] and want to discuss with you what a delegation plan may look like for figuring out which parts I should delegate to an AI like you vs. not. Can you help me with this?"

## Description

> The art of **communicating your needs** to AI

There is much similarity between describing a task to an AI and describing it to a human.

* **Product Description:** What you want, the end result
    * Output, format, audience, style, etc
* **Process Description:** The way to success, the thought process
    * Specific approaches, tools, methods, data, preferred order, etc
* **Performance Description:** AI general behavior
    * Role and tone; concise or detailed; challenging or supportive?

### Prompt Engineering

Before moving on to more advanced techniques such as RAG and fine-tuning, try prompt engineering first.

As a first step, **ask the AI itself to help improve your prompt**; successful prompting is **iterative**.

A good prompt is structured using `<XML_tags>` and `{{{VARIABLES}}}` and consists of the following:

```{.julia}

Role: {{ROLE}} # <1>
Tone: {{TONE}}

<request>
{{REQUEST}}
</request>

<context> # <2>
{{CONTEXT}}
</context>

<example> # <3>
{{EXAMPLE}}
</example>

<constraints> # <4>
{{CONSTRAINTS}}
</constraints>

<steps> # <5>
Let's think step-by-step.

1. Output an overview of every dimension of my request.
2. Find points of uncertainty.
3. Ask as many clarifying questions as needed
</steps>

Before answering, please think through this problem carefully. # <6>
Consider the different factors involved, potential constraints,
and various approaches before recommending the best solution.

Compose three different answers, and then recommend one of them. # <7>
```
1. **Role or tone:** Specify how you want the AI to communicate
2. **Context:** Be specific about **what you want**, **why** you want it, and the relevant **background**
3. **Example(s):** Demonstrate the output **style** or **format** you're looking for.
Called "n-shot" prompting, where "n" is the number of examples given.
4. **Constraint(s):** Clearly define format, length, and other **output requirements**
5. **Steps:** Guide the AI through multi-step reasoning, forcing the model to say things out loud.
Called "Chain of thought" (CoT) prompting.
6. Asking the AI to **think first.**
Give space for the AI to work through its process.
7. Ask for **multiple answers**.
This is especially helpful for boosting creativity.

For more helpful tips and examples, see:

* Anthropic's [Prompt Engineering Overview](https://docs.claude.com/en/docs/build-with-claude/prompt-engineering/overview)
* OpenAI's [OpenAI Cookbook](https://cookbook.openai.com/)
* Google's [Prompt Design Strategies](https://ai.google.dev/gemini-api/docs/prompting-strategies)

### Fine-tuning

Fine-tuning updates the LLM itself, essentially resulting in a **new model**.

A good use is for **behavior alignment** (reasoning format, style, classification logic) or domains with **static knowledge**.

### Retrieval-augmented Generation (RAG)

RAG keeps the LLM as-is and adds a **static** library.

A good use for RAG is as **knowledge augmentation** where new knowledge is added often, and the latest, accurate information retrieval is crucial.

### Model context protocol (MCP)

MCP, just like RAG, keeps the LLM as-is, but adds a **dynamic** library.
It's a protocol for LLMs to communicate with external services and tools.

## Discernment

> The art of evaluating **how well your needs were met** by AI

* **Product Discernment:** Evaluating the quality of AI outputs
    * Accuracy, appropriateness, coherence, relevance
* **Process Discernment:** Evaluating how the AI approached the task
    * Logical errors, attention gaps, circular reasoning
* **Performance Discernment:** Evaluating how the AI is communicating with you
    * Is the communication style effective?

> When **discernment** flags a problem, a better **description** is often the solution, and sometimes the **delegation** needs adjustment.

### Giving feedback to the AI

* Specifying the problem
* Clearly explaining why it is a problem
* Providing concrete suggestions for improvement
* Revising your instructions or examples

## Diligence

## Tools

### Coding agents

Coding agents are AI products like Anthropic's *Claude Code* and OpenAI's *Codex*.
Some tips that I've found helpful when working with these tools are:

* Start with brainstorming/planning, then move on to implementation
* Commit *often*, with small and focused commits
* Always write a *test* so that the AI can iterate (called *test-driven development*)
* New problem = new chat; clear the context and start fresh.

### Models

![](../images/llm_r.png){#fig-llm-r}

### R packages

* mcptools
* btw
* ellmer
* chores
* gander
* mall

## References

* Anthropic
* Simon P. Couch
* Sara Altman

::: {#refs}
:::
